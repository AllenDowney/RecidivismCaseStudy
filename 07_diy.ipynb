{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Recidivism Case Study\n",
    "\n",
    "Copyright 2020 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "This is the seventh in a series of notebooks that make up a [case study on classification and algorithmic fairness](https://allendowney.github.io/RecidivismCaseStudy/).\n",
    "This case study is part of the [*Elements of Data Science*](https://allendowney.github.io/ElementsOfDataScience/) curriculum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values(series):\n",
    "    \"\"\"Count the values and sort.\n",
    "    \n",
    "    series: pd.Series\n",
    "    \n",
    "    returns: series mapping from values to frequencies\n",
    "    \"\"\"\n",
    "    return series.value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The authors of \"Machine Bias\" published their data and analysis at <https://github.com/propublica/compas-analysis>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "The terms of use for the data are at <https://www.propublica.org/datastore/terms>.  In compliance with those terms, I am not redistributing the data.\n",
    "The following cell downloads the data file we'll use directly from their repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "\n",
    "download('https://github.com/propublica/compas-analysis/raw/master/' +\n",
    "         'compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas to read the data file and make a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7214, 53)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cp = pd.read_csv('compas-scores-two-years.csv')\n",
    "cp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 7214 rows, one for each defendant, and 53 columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Here are the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "I have not found documentation for the columns in this dataset; we have to infer what they mean based on the column names and how they are used in the original analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = int(len(cp) * 0.3)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2164"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled = cp.sample(frac=1)\n",
    "train = shuffled.iloc[:split]\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = shuffled.iloc[split:].copy()\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606212\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>two_year_recid</td>  <th>  No. Observations:  </th>  <td>  2164</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2161</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 16 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.1190</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:52:48</td>     <th>  Log-Likelihood:    </th> <td> -1311.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1489.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.185e-77</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    1.0202</td> <td>    0.149</td> <td>    6.832</td> <td> 0.000</td> <td>    0.728</td> <td>    1.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>          <td>   -0.0530</td> <td>    0.004</td> <td>  -11.770</td> <td> 0.000</td> <td>   -0.062</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>priors_count</th> <td>    0.1761</td> <td>    0.013</td> <td>   13.640</td> <td> 0.000</td> <td>    0.151</td> <td>    0.201</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:         two_year_recid   No. Observations:                 2164\n",
       "Model:                          Logit   Df Residuals:                     2161\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 16 Mar 2023   Pseudo R-squ.:                  0.1190\n",
       "Time:                        17:52:48   Log-Likelihood:                -1311.8\n",
       "converged:                       True   LL-Null:                       -1489.0\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.185e-77\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        1.0202      0.149      6.832      0.000       0.728       1.313\n",
       "age             -0.0530      0.004    -11.770      0.000      -0.062      -0.044\n",
       "priors_count     0.1761      0.013     13.640      0.000       0.151       0.201\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = 'two_year_recid ~ age + priors_count'\n",
    "results = smf.logit(formula, data=train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5050.000000\n",
       "mean        0.449932\n",
       "std         0.194447\n",
       "min         0.023870\n",
       "25%         0.318012\n",
       "50%         0.450732\n",
       "75%         0.547410\n",
       "max         0.996028\n",
       "Name: logit_pred, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['logit_pred'] = results.predict(test)\n",
    "test['logit_pred'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2500\n",
       "True     2550\n",
       "Name: HighRisk, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_risk = (test['logit_pred'] > 0.45)\n",
    "high_risk.name = 'HighRisk'\n",
    "values(high_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2772\n",
       "1    2278\n",
       "Name: two_year_recid, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values(test['two_year_recid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2772\n",
       "True     2278\n",
       "Name: NewCharge2, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_charge_2 = (test['two_year_recid'] == 1)\n",
    "new_charge_2.name = 'NewCharge2'\n",
    "values(new_charge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3317\n",
       "True     1733\n",
       "Name: white, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white = (test['race'] == 'Caucasian')\n",
    "white.name = 'white'\n",
    "values(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2504\n",
       "True     2546\n",
       "Name: black, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black = (test['race'] == 'African-American')\n",
    "black.name = 'black'\n",
    "values(black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017821782178218"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male = (test['sex'] == 'Male')\n",
    "male.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19821782178217823"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female = (test['sex'] == 'Female')\n",
    "female.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [],
   "source": [
    "def make_matrix(cp, threshold=0.45):\n",
    "    \"\"\"Make a confusion matrix.\n",
    "\n",
    "    cp: DataFrame\n",
    "    threshold: \n",
    "\n",
    "    returns: DataFrame containing the confusion matrix\n",
    "    \"\"\"\n",
    "    a = np.where(cp['logit_pred'] > threshold,\n",
    "                 'Positive',\n",
    "                 'Negative')\n",
    "    high_risk = pd.Series(a, name='Predicted')\n",
    "\n",
    "    a = np.where(cp['two_year_recid'] == 1,\n",
    "                 'Condition',\n",
    "                 'No Condition')\n",
    "    new_charge_2 = pd.Series(a, name='Actual')\n",
    "\n",
    "    matrix = pd.crosstab(high_risk, new_charge_2)\n",
    "    matrix.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "Here are the confusion matrices for white defendants, black defendants, and all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1564</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>714</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive        1564           986\n",
       "Negative         714          1786"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_all = make_matrix(test)\n",
    "matrix_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>375</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>316</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive         375           268\n",
       "Negative         316           774"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_white = make_matrix(test[white])\n",
    "matrix_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1034</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>268</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive        1034           586\n",
       "Negative         268           658"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_black = make_matrix(test[black])\n",
    "matrix_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1357</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>576</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive        1357           786\n",
       "Negative         576          1330"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_male = make_matrix(test[male])\n",
    "matrix_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>138</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive         207           200\n",
       "Negative         138           456"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_female = make_matrix(test[female])\n",
    "matrix_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(x, y):\n",
    "    \"\"\"Compute the percentage `x/(x+y)*100`.\"\"\"\n",
    "    return x / (x+y) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_value(m):\n",
    "    \"\"\"Compute positive and negative predictive value.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = m.to_numpy().flatten()\n",
    "    ppv = percent(tp, fp)\n",
    "    npv = percent(tn, fn)\n",
    "    return ppv, npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sens_spec(m):\n",
    "    \"\"\"Compute sensitivity and specificity.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = m.to_numpy().flatten()\n",
    "    sens = percent(tp, fn)\n",
    "    spec = percent(tn, fp)\n",
    "    return sens, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rates(m):\n",
    "    \"\"\"Compute false positive and false negative rate.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = m.to_numpy().flatten()\n",
    "    fpr = percent(fp, tn)\n",
    "    fnr = percent(fn, tp)\n",
    "    return fpr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prevalence(df):\n",
    "    \"\"\"Compute prevalence.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = df.to_numpy().flatten()\n",
    "    prevalence = percent(tp+fn, tn+fp)\n",
    "    return prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(m, name=''):\n",
    "    \"\"\"Compute all metrics.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    fpr, fnr = error_rates(m)\n",
    "    ppv, npv = predictive_value(m)\n",
    "    prev = prevalence(m)\n",
    "    \n",
    "    index = ['FP rate', 'FN rate', 'PPV', 'NPV', 'Prevalence']\n",
    "    df = pd.DataFrame(index=index, columns=['Percent'])\n",
    "    df.Percent = fpr, fnr, ppv, npv, prev\n",
    "    df.index.name = name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the metrics for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>35.569986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>31.343284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>61.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>71.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>45.108911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Percent\n",
       "All defendants           \n",
       "FP rate         35.569986\n",
       "FN rate         31.343284\n",
       "PPV             61.333333\n",
       "NPV             71.440000\n",
       "Prevalence      45.108911"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_all, 'All defendants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the same metrics for black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>47.106109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>20.583717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>63.827160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>71.058315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>51.139042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Percent\n",
       "Black defendants           \n",
       "FP rate           47.106109\n",
       "FN rate           20.583717\n",
       "PPV               63.827160\n",
       "NPV               71.058315\n",
       "Prevalence        51.139042"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_black, 'Black defendants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for white defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>25.719770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>45.730825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>58.320373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>71.009174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>39.873053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Percent\n",
       "White defendants           \n",
       "FP rate           25.719770\n",
       "FN rate           45.730825\n",
       "PPV               58.320373\n",
       "NPV               71.009174\n",
       "Prevalence        39.873053"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_white, 'White defendants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>37.145558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>29.798241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>63.322445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>69.779643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>47.740183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Percent\n",
       "Male defendants           \n",
       "FP rate          37.145558\n",
       "FN rate          29.798241\n",
       "PPV              63.322445\n",
       "NPV              69.779643\n",
       "Prevalence       47.740183"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_male, 'Male defendants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>30.487805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>50.859951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>76.767677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>34.465534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Percent\n",
       "Female defendants           \n",
       "FP rate            30.487805\n",
       "FN rate            40.000000\n",
       "PPV                50.859951\n",
       "NPV                76.767677\n",
       "Prevalence         34.465534"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_female, 'Female defendants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = (cp['sex'] == 'Male')\n",
    "female = (cp['sex'] == 'Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619925\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Intercept       1.052066\n",
       "age            -0.049538\n",
       "priors_count    0.149677\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'two_year_recid ~ age + priors_count'\n",
    "results = smf.logit(formula, data=cp[male]).fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.587841\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Intercept       0.198587\n",
       "age            -0.037953\n",
       "priors_count    0.219181\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'two_year_recid ~ age + priors_count'\n",
    "results = smf.logit(formula, data=cp[female]).fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'juv_fel_count', 'juv_misd_count', \n",
    "            'juv_other_count', 'priors_count']\n",
    "\n",
    "features = ['age', 'priors_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cp[features].values\n",
    "np.isnan(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = cp['two_year_recid'].values\n",
    "np.isnan(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      4\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logisticRegr.score(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
