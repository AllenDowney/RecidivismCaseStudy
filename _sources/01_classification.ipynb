{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "This is the first in a series of notebooks that make up a [case study on classification and algorithmic fairness](https://allendowney.github.io/RecidivismCaseStudy/).\n",
    "This case study is part of the [*Elements of Data Science*](https://allendowney.github.io/ElementsOfDataScience/) curriculum.\n",
    "[Click here to run this notebook on Colab](https://colab.research.google.com/github/AllenDowney/RecidivismCaseStudy/blob/v1/01_classification.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter and the next make up a case study related to \"Machine Bias\", an article published by ProPublica in 2016 (see <https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing>).\n",
    "The article explores the use of predictive algorithms in the criminal justice system. \n",
    "\n",
    "* In this chapter, we'll replicate the analysis described in the article and compute statistics that evaluate these algorithms, including accuracy, predictive value, false positive rate, and false negative rate.\n",
    "\n",
    "* In the next chapter, we'll review arguments presented in a response article published in the Washington Post.  We'll compute and interpret calibration curves, and explore the trade-offs between predictive value and error rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "* In the third chapter, I apply the same analysis to evaluate the performance of classification for male and female defendants.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Bias\n",
    "\n",
    "We'll start by replicating the analysis reported in\n",
    "\"Machine Bias\", by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, and published by ProPublica in May 2016.\n",
    "\n",
    "This article is about a statistical tool called COMPAS which is used in some criminal justice systems to inform decisions about which defendants should be released on bail before trial, how long convicted defendants should be imprisoned, and whether prisoners should be released on probation.\n",
    "COMPAS uses information about defendants to generate a \"risk score\" which is intended to quantify the risk that the defendant would commit another crime if released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "Read more about COMPAS at <https://en.wikipedia.org/wiki/COMPAS_(software)>.\n",
    "\n",
    "See the ProPublica analysis of the data at <https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of the ProPublica article used public data to assess the accuracy of those risk scores. They explain:\n",
    "\n",
    "> We obtained the risk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014 and checked to see how many were charged with new crimes over the next two years, the same benchmark used by the creators of the algorithm.\n",
    "\n",
    "In the notebook that contains their analysis, they explain in more detail:\n",
    "\n",
    "> We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
    ">\n",
    "> [...]\n",
    ">\n",
    "> Next, we sought to determine if a person had been charged with a new crime subsequent to the crime for which they were COMPAS screened. We did not count traffic tickets and some municipal ordinance violations as recidivism. We did not count as recidivists people who were arrested for failing to appear at their court hearings, or people who were later charged with a crime that occurred prior to their COMPAS screening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not familiar with the word \"recidivism\", it usually means a tendency to relapse into criminal behavior.\n",
    "In this context, a person is a \"recidivist\" if they are charged with another crime within two years of release.  However, note that there is a big difference between *committing* another crime and being *charged* with another crime.  We will come back to this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of the ProPublica article use this data to evaluate how well COMPAS predicts the risk that a defendant will be charged with another crime within two years of their release.\n",
    "Among their findings, they report:\n",
    "\n",
    "> ... the algorithm was somewhat more accurate than a coin flip. Of those deemed likely to re-offend, 61 percent were arrested for any subsequent crimes within two years.\n",
    "> \n",
    "> ... In forecasting who would re-offend, the algorithm made mistakes with Black and White defendants at roughly the same rate but in very different ways.\n",
    ">\n",
    "> * The formula was particularly likely to falsely flag Black defendants as future criminals, wrongly labeling them this way at almost twice the rate as White defendants.\n",
    ">\n",
    "> * White defendants were mislabeled as low risk more often than Black defendants.\n",
    "\n",
    "This discrepancy suggests that the use of COMPAS in the criminal justice system is racially biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ProPublica article was published, it has been widely discussed in the media, and a number of researchers have published responses.  In order to evaluate the original article and the responses it provoked, there are some technical issues you need to understand.  My goal is to help you analyze the arguments and interpret the statistics they are based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"from os.path import basename, exists\\n\\n\\ndef download(url):\\n    filename = basename(url)\\n    if not exists(filename):\\n        from urllib.request import urlretrieve\\n\\n        local, _ = urlretrieve(url, filename)\\n        print(\\\"Downloaded \\\" + local)\\n\\n\\ndownload(\\n    \\\"https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/v1/utils.py\\\"\\n)\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"from os.path import basename, exists\\n\\n\\ndef download(url):\\n    filename = basename(url)\\n    if not exists(filename):\\n        from urllib.request import urlretrieve\\n\\n        local, _ = urlretrieve(url, filename)\\n        print(\\\"Downloaded \\\" + local)\\n\\n\\ndownload(\\n    \\\"https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/v1/utils.py\\\"\\n)\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print(\"Downloaded \" + local)\n",
    "\n",
    "\n",
    "download(\n",
    "    \"https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/v1/utils.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating the Analysis\n",
    "\n",
    "The data used in \"Machine Bias\" is available from <https://github.com/propublica/compas-analysis>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "The terms of use for the data are at <https://www.propublica.org/datastore/terms>.  In compliance with those terms, I am not redistributing the data.\n",
    "The following cell downloads the data file we'll use directly from their repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"download(\\n    \\\"https://github.com/propublica/compas-analysis/raw/master/compas-scores-two-years.csv\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"download(\\n    \\\"https://github.com/propublica/compas-analysis/raw/master/compas-scores-two-years.csv\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download(\n",
    "    \"https://github.com/propublica/compas-analysis/raw/master/compas-scores-two-years.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Pandas to read the file and make a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7214, 53)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\n\\ncp = pd.read_csv(\\\"compas-scores-two-years.csv\\\")\\ncp.shape\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\n\\ncp = pd.read_csv(\\\"compas-scores-two-years.csv\\\")\\ncp.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cp = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "cp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 7214 rows, one for each defendant, and 53 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Here are the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"cp.columns\";\n",
       "                var nbb_formatted_code = \"cp.columns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "I have not found documentation for the columns in this dataset; we have to infer what they mean based on the column names and how they are used in the original analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of \"Machine Bias\" describe their analysis in a supplemental article at <https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm>.  It includes this table, which summarizes many of the results they report:\n",
    "\n",
    "![](https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/v1/machine_bias_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table summarizes results for all defendants and two subgroups: defendants classified as White (\"Caucasian\" in the original dataset) and Black (\"African-American\").\n",
    "For each group, the summary includes several metrics, including:\n",
    "\n",
    "* FP rate: false positive rate\n",
    "* FN rate: false negative rate\n",
    "* PPV: positive predictive value\n",
    "* NPV: negative predictive value\n",
    "* LR+: positive likelihood ratio \n",
    "* LR-: negative likelihood ratio \n",
    "\n",
    "I will explain what these metrics mean and how to compute them, and we'll replicate the results in this table.\n",
    "But first let's examine the data and compute some recoded variables.\n",
    "The following function displays the values in a Series and the number of times each value appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def values(series):\\n    \\\"\\\"\\\"Count the values and sort.\\n\\n    series: pd.Series\\n\\n    returns: series mapping from values to frequencies\\n    \\\"\\\"\\\"\\n    return series.value_counts(dropna=False).sort_index()\";\n",
       "                var nbb_formatted_code = \"def values(series):\\n    \\\"\\\"\\\"Count the values and sort.\\n\\n    series: pd.Series\\n\\n    returns: series mapping from values to frequencies\\n    \\\"\\\"\\\"\\n    return series.value_counts(dropna=False).sort_index()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def values(series):\n",
    "    \"\"\"Count the values and sort.\n",
    "\n",
    "    series: pd.Series\n",
    "\n",
    "    returns: series mapping from values to frequencies\n",
    "    \"\"\"\n",
    "    return series.value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the values of `decile_score`, which is the output of the COMPAS algorithm.\n",
    "`1` is the lowest risk category; `10` is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decile_score\n",
       "1     1440\n",
       "2      941\n",
       "3      747\n",
       "4      769\n",
       "5      681\n",
       "6      641\n",
       "7      592\n",
       "8      512\n",
       "9      508\n",
       "10     383\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"values(cp[\\\"decile_score\\\"])\";\n",
       "                var nbb_formatted_code = \"values(cp[\\\"decile_score\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values(cp[\"decile_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that COMPAS is not a binary classifier; that is, it does not predict that a defendant will or will not recidivate.  Rather, it gives each defendant a score that is intended to reflect the risk that they will recidivate.\n",
    "\n",
    "In order to evaluate the performance of COMPAS, the authors of the ProPublica article chose a threshold, `4`, and defined decile scores at or below the threshold to be \"low risk\", and scores above the threshold to be \"high risk\".\n",
    "Their choice of the threshold is arbitrary.  Later, we will see what happens with other choices, but we'll start by replicating the original analysis.\n",
    "\n",
    "We'll create a Boolean `Series` called `high_risk` that's `True` for respondents with a decile score greater than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighRisk\n",
       "False    3897\n",
       "True     3317\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"high_risk = cp[\\\"decile_score\\\"] > 4\\nhigh_risk.name = \\\"HighRisk\\\"\\nvalues(high_risk)\";\n",
       "                var nbb_formatted_code = \"high_risk = cp[\\\"decile_score\\\"] > 4\\nhigh_risk.name = \\\"HighRisk\\\"\\nvalues(high_risk)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "high_risk = cp[\"decile_score\"] > 4\n",
    "high_risk.name = \"HighRisk\"\n",
    "values(high_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `two_year_recid` indicates whether a defendant was charged with another crime during a two year period after the original charge when they were not in a correctional facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two_year_recid\n",
       "0    3963\n",
       "1    3251\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"values(cp[\\\"two_year_recid\\\"])\";\n",
       "                var nbb_formatted_code = \"values(cp[\\\"two_year_recid\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values(cp[\"two_year_recid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another `Series`, called `new_charge`, that is `True` for defendants who were charged with another crime within two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewCharge\n",
       "False    3963\n",
       "True     3251\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"new_charge = cp[\\\"two_year_recid\\\"] == 1\\nnew_charge.name = \\\"NewCharge\\\"\\nvalues(new_charge)\";\n",
       "                var nbb_formatted_code = \"new_charge = cp[\\\"two_year_recid\\\"] == 1\\nnew_charge.name = \\\"NewCharge\\\"\\nvalues(new_charge)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_charge = cp[\"two_year_recid\"] == 1\n",
    "new_charge.name = \"NewCharge\"\n",
    "values(new_charge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make a cross-tabulation of `new_charge` and `high_risk`, the result is a DataFrame that indicates how many defendants are in each of four groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HighRisk</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewCharge</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2681</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1216</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HighRisk   False  True \n",
       "NewCharge              \n",
       "False       2681   1282\n",
       "True        1216   2035"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"pd.crosstab(new_charge, high_risk)\";\n",
       "                var nbb_formatted_code = \"pd.crosstab(new_charge, high_risk)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(new_charge, high_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is called a **confusion matrix** or error matrix.  Reading from left to right and top to bottom, the elements of the matrix show the number of respondents who were:\n",
    "\n",
    "* Classified as low risk and not charged with a new crime: there were 2681 **true negatives**; that is, cases where the test was negative (not high risk) and the prediction turned out to be correct (no new charge).\n",
    "\n",
    "* High risk and not charged: there were 1282 **false positives**, cases where the test was positive and the prediction was incorrect.\n",
    "\n",
    "* Low risk and charged: there were 1216 **false negatives**, cases where the test was negative (low risk) and the prediction was incorrect (the defendant was charged with a new crime).\n",
    "\n",
    "* High risk and charged: there were 2035 **true positives**, cases where the test was positive and the prediction was correct.\n",
    "\n",
    "The values in this matrix are consistent with the values in the ProPublica article, so we can confirm that we are reading the data and replicating their analysis correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the confusion matrices for White and Black defendants.\n",
    "Here are the values of `race`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "African-American    3696\n",
       "Asian                 32\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Native American       18\n",
       "Other                377\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"values(cp[\\\"race\\\"])\";\n",
       "                var nbb_formatted_code = \"values(cp[\\\"race\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values(cp[\"race\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a Boolean `Series` that's true for White defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white\n",
       "False    4760\n",
       "True     2454\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"white = cp[\\\"race\\\"] == \\\"Caucasian\\\"\\nwhite.name = \\\"white\\\"\\nvalues(white)\";\n",
       "                var nbb_formatted_code = \"white = cp[\\\"race\\\"] == \\\"Caucasian\\\"\\nwhite.name = \\\"white\\\"\\nvalues(white)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "white = cp[\"race\"] == \"Caucasian\"\n",
    "white.name = \"white\"\n",
    "values(white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the confusion matrix for White defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HighRisk</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewCharge</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1139</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>461</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HighRisk   False  True \n",
       "NewCharge              \n",
       "False       1139    349\n",
       "True         461    505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"pd.crosstab(new_charge[white], high_risk[white])\";\n",
       "                var nbb_formatted_code = \"pd.crosstab(new_charge[white], high_risk[white])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(new_charge[white], high_risk[white])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`black` is a Boolean Series that is `True` for Black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "black\n",
       "False    3518\n",
       "True     3696\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"black = cp[\\\"race\\\"] == \\\"African-American\\\"\\nblack.name = \\\"black\\\"\\nvalues(black)\";\n",
       "                var nbb_formatted_code = \"black = cp[\\\"race\\\"] == \\\"African-American\\\"\\nblack.name = \\\"black\\\"\\nvalues(black)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "black = cp[\"race\"] == \"African-American\"\n",
    "black.name = \"black\"\n",
    "values(black)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the confusion matrix for Black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HighRisk</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewCharge</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>990</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>532</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HighRisk   False  True \n",
       "NewCharge              \n",
       "False        990    805\n",
       "True         532   1369"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"pd.crosstab(new_charge[black], high_risk[black])\";\n",
       "                var nbb_formatted_code = \"pd.crosstab(new_charge[black], high_risk[black])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(new_charge[black], high_risk[black])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these results are consistent with the ProPublica article.\n",
    "However, before we go on, I want to address an important issue with this dataset: data bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Bias\n",
    "\n",
    "Systems like COMPAS are trying to predict whether a defendant will *commit* another crime if released.  But the dataset reports whether a defendant was *charged* with another crime.\n",
    "\n",
    "Not everyone who commits a crime gets charged (not even close).  The probability of getting charged for a particular crime depends on the type of crime and location; the presence of witnesses and their willingness to work with police; the decisions of police about where to patrol, what crimes to investigate, and who to arrest; and decisions of prosecutors about who to charge.\n",
    "\n",
    "It is likely that every one of these factors depends on the race of the defendant.  In this dataset, the prevalence of *new charges* is higher for Black defendants, but that doesn't necessarily mean that the prevalence of *new crimes* is higher.  \n",
    "\n",
    "If the dataset is affected by racial bias in the probability of being charged, prediction algorithms like COMPAS will be biased, too.  In discussions of whether and how these systems should be used in the criminal justice system, this is an important issue.  \n",
    "\n",
    "However, I am going to put it aside *for now* in order to focus on understanding the arguments posed in the ProPublica article and the metrics they are based on.  For the rest of this chapter I will take the \"recidivism rates\" in the dataset at face value; but I will try to be clear about that they mean (and don't mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the confusion matrix\n",
    "\n",
    "In the previous section I arranged the confusion matrix to be consistent with the ProPublica article, to make it easy to check for consistency.\n",
    "\n",
    "In general, there are many ways to arrange a confusion matrix: you can put the predictions along the columns and the actual conditions along the rows, or the other way around, and you can sort the rows and columns in either order.\n",
    "\n",
    "There is no universal standard arrangement, but the most common one looks like this:\n",
    "\n",
    "|                     | **Predicted positive** | **Predicted negative** |\n",
    "|---------------------|------------------------|------------------------|\n",
    "| **Actual positive** | True positive (TP)     | False negative (FN)    |\n",
    "| **Actual negative** | False positive (FP)    | True negative (TN)     |\n",
    "\n",
    "In this arrangement:\n",
    "\n",
    "* The actual conditions are down the rows.\n",
    "\n",
    "* The predictions are across the columns.\n",
    "\n",
    "* The rows and columns are sorted so true positives are in the upper left and true negatives are in the lower right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of the ProPublica article:\n",
    "\n",
    "* \"Predicted positive\" means the defendant is classified as high risk.\n",
    "\n",
    "* \"Predicted negative\" means low risk.\n",
    "\n",
    "* \"Actual positive\" means the defendant was charged with a new crime (recidivated).\n",
    "\n",
    "* \"Actual negative\" means they were not charged (survived)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "The following function makes a confusion matrix with this arrangement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\n\\n\\ndef make_matrix(cp, threshold=4):\\n    \\\"\\\"\\\"Make a confusion matrix.\\n\\n    cp: DataFrame\\n    threshold: default is 4\\n\\n    returns: DataFrame containing the confusion matrix\\n    \\\"\\\"\\\"\\n    a = np.where(cp[\\\"decile_score\\\"] > threshold, \\\"Pred Positive\\\", \\\"Pred Negative\\\")\\n    high_risk = pd.Series(a, name=\\\"\\\")\\n\\n    a = np.where(cp[\\\"two_year_recid\\\"] == 1, \\\"Positive\\\", \\\"Negative\\\")\\n    new_charge = pd.Series(a, name=\\\"Actual\\\")\\n\\n    matrix = pd.crosstab(new_charge, high_risk)\\n    matrix.sort_index(axis=0, ascending=False, inplace=True)\\n    matrix.sort_index(axis=1, ascending=False, inplace=True)\\n\\n    return matrix\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\n\\n\\ndef make_matrix(cp, threshold=4):\\n    \\\"\\\"\\\"Make a confusion matrix.\\n\\n    cp: DataFrame\\n    threshold: default is 4\\n\\n    returns: DataFrame containing the confusion matrix\\n    \\\"\\\"\\\"\\n    a = np.where(cp[\\\"decile_score\\\"] > threshold, \\\"Pred Positive\\\", \\\"Pred Negative\\\")\\n    high_risk = pd.Series(a, name=\\\"\\\")\\n\\n    a = np.where(cp[\\\"two_year_recid\\\"] == 1, \\\"Positive\\\", \\\"Negative\\\")\\n    new_charge = pd.Series(a, name=\\\"Actual\\\")\\n\\n    matrix = pd.crosstab(new_charge, high_risk)\\n    matrix.sort_index(axis=0, ascending=False, inplace=True)\\n    matrix.sort_index(axis=1, ascending=False, inplace=True)\\n\\n    return matrix\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_matrix(cp, threshold=4):\n",
    "    \"\"\"Make a confusion matrix.\n",
    "\n",
    "    cp: DataFrame\n",
    "    threshold: default is 4\n",
    "\n",
    "    returns: DataFrame containing the confusion matrix\n",
    "    \"\"\"\n",
    "    a = np.where(cp[\"decile_score\"] > threshold, \"Pred Positive\", \"Pred Negative\")\n",
    "    high_risk = pd.Series(a, name=\"\")\n",
    "\n",
    "    a = np.where(cp[\"two_year_recid\"] == 1, \"Positive\", \"Negative\")\n",
    "    new_charge = pd.Series(a, name=\"Actual\")\n",
    "\n",
    "    matrix = pd.crosstab(new_charge, high_risk)\n",
    "    matrix.sort_index(axis=0, ascending=False, inplace=True)\n",
    "    matrix.sort_index(axis=1, ascending=False, inplace=True)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, we'll present confusion matrices in this format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "Here are the confusion matrices for White and Black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Positive</th>\n",
       "      <th>Pred Negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>505</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>349</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred Positive  Pred Negative\n",
       "Actual                                \n",
       "Positive            505            461\n",
       "Negative            349           1139"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"matrix_white = make_matrix(cp[white])\\nmatrix_white\";\n",
       "                var nbb_formatted_code = \"matrix_white = make_matrix(cp[white])\\nmatrix_white\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix_white = make_matrix(cp[white])\n",
    "matrix_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Positive</th>\n",
       "      <th>Pred Negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1369</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>805</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred Positive  Pred Negative\n",
       "Actual                                \n",
       "Positive           1369            532\n",
       "Negative            805            990"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"matrix_black = make_matrix(cp[black])\\nmatrix_black\";\n",
       "                var nbb_formatted_code = \"matrix_black = make_matrix(cp[black])\\nmatrix_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix_black = make_matrix(cp[black])\n",
    "matrix_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the confusion matrix for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Positive</th>\n",
       "      <th>Pred Negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>2035</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1282</td>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred Positive  Pred Negative\n",
       "Actual                                \n",
       "Positive           2035           1216\n",
       "Negative           1282           2681"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"matrix_all = make_matrix(cp)\\nmatrix_all\";\n",
       "                var nbb_formatted_code = \"matrix_all = make_matrix(cp)\\nmatrix_all\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix_all = make_matrix(cp)\n",
    "matrix_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Based on these results, how accurate is COMPAS as a binary classifier?  Well, it turns out that there are a *lot* of ways to answer that question.\n",
    "One of the simplest is overall **accuracy**, which is the fraction (or percentage) of correct predictions.\n",
    "To compute accuracy, it is convenient to extract from the confusion matrix the number of true positives, false negatives, false positives, and true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"tp, fn, fp, tn = matrix_all.to_numpy().flatten()\";\n",
       "                var nbb_formatted_code = \"tp, fn, fp, tn = matrix_all.to_numpy().flatten()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp, fn, fp, tn = matrix_all.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true predictions is `tp + tn`.\n",
    "The number of false predictions is `fp + fn`.\n",
    "So we can compute the fraction of true predictions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def percent(x, y):\\n    \\\"\\\"\\\"Compute the percentage `x/(x+y)*100`.\\\"\\\"\\\"\\n    return x / (x + y) * 100\";\n",
       "                var nbb_formatted_code = \"def percent(x, y):\\n    \\\"\\\"\\\"Compute the percentage `x/(x+y)*100`.\\\"\\\"\\\"\\n    return x / (x + y) * 100\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def percent(x, y):\n",
    "    \"\"\"Compute the percentage `x/(x+y)*100`.\"\"\"\n",
    "    return x / (x + y) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.37288605489326"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"accuracy = percent(tp + tn, fp + fn)\\naccuracy\";\n",
       "                var nbb_formatted_code = \"accuracy = percent(tp + tn, fp + fn)\\naccuracy\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = percent(tp + tn, fp + fn)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way to evaluate a binary classifier, accuracy does not distinguish between true positives and true negatives, or false positives and false negatives.\n",
    "\n",
    "But it is often important to make these distinctions, because the benefits of true predictions and true negatives might be different, and the costs of false positives and false negatives might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Value\n",
    "\n",
    "One way to make these distinctions is to compute the \"predictive value\" of positive and negative tests:\n",
    "\n",
    "* **Positive predictive value (PPV)** is the fraction of positive tests that are correct.\n",
    "\n",
    "* **Negative predictive value (NPV)** is the fraction of negative tests that are correct.\n",
    "\n",
    "In this example, PPV is the fraction of high risk defendants who were charged with a new crime.  NPV is the fraction of low risk defendants who \"survived\" a two year period without being charged.\n",
    "\n",
    "The following function takes a confusion matrix and computes these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"def predictive_value(m):\\n    \\\"\\\"\\\"Compute positive and negative predictive value.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    ppv = percent(tp, fp)\\n    npv = percent(tn, fn)\\n    return ppv, npv\";\n",
       "                var nbb_formatted_code = \"def predictive_value(m):\\n    \\\"\\\"\\\"Compute positive and negative predictive value.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    ppv = percent(tp, fp)\\n    npv = percent(tn, fn)\\n    return ppv, npv\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predictive_value(m):\n",
    "    \"\"\"Compute positive and negative predictive value.\n",
    "\n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fn, fp, tn = m.to_numpy().flatten()\n",
    "    ppv = percent(tp, fp)\n",
    "    npv = percent(tn, fn)\n",
    "    return ppv, npv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictive values for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61.350618028338864, 68.79651013600206)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"ppv, npv = predictive_value(matrix_all)\\nppv, npv\";\n",
       "                var nbb_formatted_code = \"ppv, npv = predictive_value(matrix_all)\\nppv, npv\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppv, npv = predictive_value(matrix_all)\n",
    "ppv, npv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all defendants, a positive test is correct about 61% of the time; a negative test result is correct about 69% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity and Specificity\n",
    "\n",
    "Another way to characterize the accuracy of a test is to compute \n",
    "\n",
    "* **Sensitivity**, which is the probability of predicting correctly when the condition is present, and \n",
    "\n",
    "* **Specificity**, which is the probability of predicting correctly when the condition is absent.\n",
    "\n",
    "A test is \"sensitive\" if it detects the positive condition. \n",
    "In this example, sensitivity is the fraction of recidivists who were correctly classified as high risk.\n",
    "\n",
    "A test is \"specific\" if it identifies the negative condition.  In this example, specificity is the fraction of non-recidivists who were correctly classified as low risk.\n",
    "\n",
    "The following function takes a confusion matrix and computes sensitivity and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def sens_spec(m):\\n    \\\"\\\"\\\"Compute sensitivity and specificity.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    sens = percent(tp, fn)\\n    spec = percent(tn, fp)\\n    return sens, spec\";\n",
       "                var nbb_formatted_code = \"def sens_spec(m):\\n    \\\"\\\"\\\"Compute sensitivity and specificity.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    sens = percent(tp, fn)\\n    spec = percent(tn, fp)\\n    return sens, spec\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sens_spec(m):\n",
    "    \"\"\"Compute sensitivity and specificity.\n",
    "\n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fn, fp, tn = m.to_numpy().flatten()\n",
    "    sens = percent(tp, fn)\n",
    "    spec = percent(tn, fp)\n",
    "    return sens, spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are sensitivity and specificity for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.59612426945556, 67.65076961897553)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"sens, spec = sens_spec(matrix_all)\\nsens, spec\";\n",
       "                var nbb_formatted_code = \"sens, spec = sens_spec(matrix_all)\\nsens, spec\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sens, spec = sens_spec(matrix_all)\n",
    "sens, spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we evaluate COMPAS as a binary classifier, it is a little more specific than sensitive:\n",
    "\n",
    "* About 63% of the recidivists were classified as high risk.\n",
    "\n",
    "* About 68% of the non-recidivists were classified as low risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be hard to keep all of these metrics straight, especially when you are learning about them for the first time.  The following table might help:\n",
    "\n",
    "|                              | **Pred positive (PP)**         | **Pred negative (PN)**         |                               |                              |\n",
    "|------------------------------|-------------------------------------|-------------------------------------|--------------------------------|------------------------------|\n",
    "| **Actual positive (P)**      | True positive (TP)                  | False negative (FN)                 | Sensitivity = TP / P            | FN rate = FN / P |\n",
    "| **Actual negative (N)**      | False positive (FP)                 | True negative (TN)                  | FP rate = FP / N   | Specificity = TN / N         |\n",
    "| Prevalence = P / (P + N) | PPV = TP / PP | NPV = TN / PN || Acc = (TP + TN) / (P + N) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPV and sensitivity are similar in the sense that they both have true positives in the numerator.  The difference is the denominator:\n",
    "\n",
    "* PPV is the ratio of true positives to all positive tests.  So it answers the question, \"Of all positive tests, how many are correct?\"\n",
    "\n",
    "* Sensitivity is the ratio of true positives to all positive conditions.  So it answers the question \"Of all positive conditions, how many are detected?\"\n",
    "\n",
    "Similarly, NPV and sensitivity both have true negatives in the numerator, but:\n",
    "\n",
    "* NPV is the ratio of true negatives to all negative tests.  It answers, \"Of all negative tests, how many are correct?\"\n",
    "\n",
    "* Specificity is the ratio of true negatives to all negative conditions.  It answers, \"Of all negative conditions, how many are classified correctly?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Positive and Negative Rates\n",
    "\n",
    "The ProPublica article reports PPV and NPV, but instead of sensitivity and specificity, it reports their complements:\n",
    "\n",
    "* **False positive rate**, which is the ratio of false positives to all negative conditions.  It answers, \"Of all negative conditions, how many are misclassified?\" \n",
    "\n",
    "* **False negative rate**, which is the ratio of false negatives to all positive conditions.  It answers, \"Of all positive conditions, how many are misclassified?\"\n",
    "\n",
    "In this example:\n",
    "\n",
    "* The false positive rate is the fraction of non-recidivists who were classified as high risk.\n",
    "\n",
    "* The false negative rate is the fraction of recidivists who were classified as low risk.\n",
    "\n",
    "The following function takes a confusion matrix and computes false positive and false negative rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"def error_rates(m):\\n    \\\"\\\"\\\"Compute false positive and false negative rate.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    fpr = percent(fp, tn)\\n    fnr = percent(fn, tp)\\n    return fpr, fnr\";\n",
       "                var nbb_formatted_code = \"def error_rates(m):\\n    \\\"\\\"\\\"Compute false positive and false negative rate.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    fpr = percent(fp, tn)\\n    fnr = percent(fn, tp)\\n    return fpr, fnr\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def error_rates(m):\n",
    "    \"\"\"Compute false positive and false negative rate.\n",
    "\n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fn, fp, tn = m.to_numpy().flatten()\n",
    "    fpr = percent(fp, tn)\n",
    "    fnr = percent(fn, tp)\n",
    "    return fpr, fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the error rates for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.349230381024476, 37.40387573054445)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"fpr, fnr = error_rates(matrix_all)\\nfpr, fnr\";\n",
       "                var nbb_formatted_code = \"fpr, fnr = error_rates(matrix_all)\\nfpr, fnr\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, fnr = error_rates(matrix_all)\n",
    "fpr, fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPR is the complement of specificity, which means they have to add up to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"fpr + spec\";\n",
       "                var nbb_formatted_code = \"fpr + spec\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr + spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And FNR is the complement of sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"fnr + sens\";\n",
       "                var nbb_formatted_code = \"fnr + sens\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fnr + sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So FPR and FNR are just another way of reporting sensitivity and specificity.\n",
    "In general, I prefer sensitivity and specificity over FPN and FNR because\n",
    "\n",
    "* I think the positive framing is easier to interpret than the negative framing, and\n",
    "\n",
    "* I find it easier to remember what \"sensitivity\" and \"specificity\" mean.\n",
    "\n",
    "I think \"false positive rate\" and \"false negative rate\" are more problematic.  For example, \"false positive rate\" could just as easily mean either\n",
    "\n",
    "1. The fraction of positive tests that are incorrect, or\n",
    "\n",
    "2. The fraction of negative conditions that are misclassified.\n",
    "\n",
    "It is only a convention that the first is called the \"false discovery rate\" and the second is called \"false positive rate\".  I suspect I am not the only one that gets them confused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here's my recommendation: if you have the choice, generally use PPV, NPV, sensitivity and specificity, and avoid the other metrics.\n",
    "However, since the ProPublica article uses FPR and FNR, I will too.\n",
    "They also report LR+ and LR-, but those are combinations of other metrics and not relevant to the current discussion, so I will ignore them.\n",
    "\n",
    "However, there is one other metric that I think is relevant and not included in the ProPublica tables: **prevalence**, which is the fraction of all cases where the condition is positive.  In the example, it's the fraction of defendants who recidivate.\n",
    "The following function computes prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"def prevalence(m):\\n    \\\"\\\"\\\"Compute prevalence.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    prevalence = percent(tp + fn, tn + fp)\\n    return prevalence\";\n",
       "                var nbb_formatted_code = \"def prevalence(m):\\n    \\\"\\\"\\\"Compute prevalence.\\n\\n    m: confusion matrix\\n    \\\"\\\"\\\"\\n    tp, fn, fp, tn = m.to_numpy().flatten()\\n    prevalence = percent(tp + fn, tn + fp)\\n    return prevalence\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prevalence(m):\n",
    "    \"\"\"Compute prevalence.\n",
    "\n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fn, fp, tn = m.to_numpy().flatten()\n",
    "    prevalence = percent(tp + fn, tn + fp)\n",
    "    return prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the prevalence for all defendants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.06515109509287"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"prev = prevalence(matrix_all)\\nprev\";\n",
       "                var nbb_formatted_code = \"prev = prevalence(matrix_all)\\nprev\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev = prevalence(matrix_all)\n",
    "prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 45% of the defendants in this dataset were charged with another crime within two years of their release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Metrics\n",
    "\n",
    "The following function takes a confusion matrix, computes all the metrics, and puts them in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"def compute_metrics(m, name=\\\"\\\"):\\n    \\\"\\\"\\\"Compute all metrics.\\n\\n    m: confusion matrix\\n\\n    returns: DataFrame\\n    \\\"\\\"\\\"\\n    fpr, fnr = error_rates(m)\\n    ppv, npv = predictive_value(m)\\n    prev = prevalence(m)\\n\\n    index = [\\\"FP rate\\\", \\\"FN rate\\\", \\\"PPV\\\", \\\"NPV\\\", \\\"Prevalence\\\"]\\n    df = pd.DataFrame(index=index, columns=[\\\"Percent\\\"])\\n    df.Percent = fpr, fnr, ppv, npv, prev\\n    df.index.name = name\\n    return df.round(1)\";\n",
       "                var nbb_formatted_code = \"def compute_metrics(m, name=\\\"\\\"):\\n    \\\"\\\"\\\"Compute all metrics.\\n\\n    m: confusion matrix\\n\\n    returns: DataFrame\\n    \\\"\\\"\\\"\\n    fpr, fnr = error_rates(m)\\n    ppv, npv = predictive_value(m)\\n    prev = prevalence(m)\\n\\n    index = [\\\"FP rate\\\", \\\"FN rate\\\", \\\"PPV\\\", \\\"NPV\\\", \\\"Prevalence\\\"]\\n    df = pd.DataFrame(index=index, columns=[\\\"Percent\\\"])\\n    df.Percent = fpr, fnr, ppv, npv, prev\\n    df.index.name = name\\n    return df.round(1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(m, name=\"\"):\n",
    "    \"\"\"Compute all metrics.\n",
    "\n",
    "    m: confusion matrix\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    fpr, fnr = error_rates(m)\n",
    "    ppv, npv = predictive_value(m)\n",
    "    prev = prevalence(m)\n",
    "\n",
    "    index = [\"FP rate\", \"FN rate\", \"PPV\", \"NPV\", \"Prevalence\"]\n",
    "    df = pd.DataFrame(index=index, columns=[\"Percent\"])\n",
    "    df.Percent = fpr, fnr, ppv, npv, prev\n",
    "    df.index.name = name\n",
    "    return df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the metrics for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Percent\n",
       "All defendants         \n",
       "FP rate            32.3\n",
       "FN rate            37.4\n",
       "PPV                61.4\n",
       "NPV                68.8\n",
       "Prevalence         45.1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"compute_metrics(matrix_all, \\\"All defendants\\\")\";\n",
       "                var nbb_formatted_code = \"compute_metrics(matrix_all, \\\"All defendants\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_metrics(matrix_all, \"All defendants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these results to the table from ProPublica, it looks like our analysis agrees with theirs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-print"
    ]
   },
   "source": [
    "![](https://raw.githubusercontent.com/AllenDowney/ElementsOfDataScience/v1/machine_bias_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the same metrics for Black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Percent\n",
       "Black defendants         \n",
       "FP rate              44.8\n",
       "FN rate              28.0\n",
       "PPV                  63.0\n",
       "NPV                  65.0\n",
       "Prevalence           51.4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"compute_metrics(matrix_black, \\\"Black defendants\\\")\";\n",
       "                var nbb_formatted_code = \"compute_metrics(matrix_black, \\\"Black defendants\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_metrics(matrix_black, \"Black defendants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for White defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>47.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>59.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Percent\n",
       "White defendants         \n",
       "FP rate              23.5\n",
       "FN rate              47.7\n",
       "PPV                  59.1\n",
       "NPV                  71.2\n",
       "Prevalence           39.4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"compute_metrics(matrix_white, \\\"White defendants\\\")\";\n",
       "                var nbb_formatted_code = \"compute_metrics(matrix_white, \\\"White defendants\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_metrics(matrix_white, \"White defendants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these results are consistent with those reported in the article, including the headline results:\n",
    "\n",
    "1. The false positive rate for Black defendants is substantially higher than for White defendants (45%, compared to 23%).\n",
    "\n",
    "2. The false negative rate for Black defendants is substantially lower (28%, compared to 48%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.84679665738162, 27.985270910047344)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"error_rates(matrix_black)\";\n",
       "                var nbb_formatted_code = \"error_rates(matrix_black)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rates(matrix_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.45430107526882, 47.72256728778468)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"error_rates(matrix_white)\";\n",
       "                var nbb_formatted_code = \"error_rates(matrix_white)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rates(matrix_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words:\n",
    "\n",
    "* Of all people who *will not* recidivate, Black defendants are more likely to be be classified as high risk and (if these classifications influence sentencing decisions) more likely to be sent to prison.\n",
    "\n",
    "* Of all people who *will* recidivate, White defendants are more likely to be classified as low risk, and more likely to be released.\n",
    "\n",
    "This seems clearly unfair.\n",
    "\n",
    "However, it turns out that \"fair\" is complicated.  After the ProPublica article, the Washington Post published a response by Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel: \"A computer program used for bail and sentencing decisions was labeled biased against blacks. Its actually not that clear,\" at <https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas>.\n",
    "\n",
    "I encourage you to read that article, and then read the next chapter, where I will unpack their arguments and replicate their analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Recidivism Case Study\n",
    "\n",
    "Copyright 2020 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
